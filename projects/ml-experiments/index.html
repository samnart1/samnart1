<!DOCTYPE html>
<html lang="en" data-theme="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML Experiments — Sam Nart</title>
    <meta name="description" content="Collection of machine learning experiments and notebooks using PyTorch and scikit-learn.">

    <!-- Open Graph -->
    <meta property="og:title" content="ML Experiments — Sam Nart">
    <meta property="og:description" content="Machine learning experiments with PyTorch and scikit-learn.">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://samnart.website/projects/ml-experiments/">

    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="/images/favicon.svg">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500&family=Newsreader:ital,wght@0,400;0,500;1,400&display=swap" rel="stylesheet">

    <!-- Styles -->
    <link rel="stylesheet" href="/css/style.css">
</head>
<body>
    <!-- Navigation -->
    <div id="nav" aria-busy="true"></div>

    
    <main class="page">
        <div class="container">
            <article class="project-detail">
                <!-- Header -->
                <header class="project-detail__header">
                    <nav class="project-detail__breadcrumb">
                        <a href="/">Home</a>
                        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"/>
                        </svg>
                        <a href="/projects/">Projects</a>
                        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"/>
                        </svg>
                        <span>ML Experiments</span>
                    </nav>

                    <div class="project-detail__top">
                        <div class="project-detail__title-group">
                            <h1 class="project-detail__title">ML Experiments</h1>
                            <div class="project-detail__meta">
                                <span class="project-detail__lang">Python</span>
                                <div class="project-detail__tags">
                                    <span class="project-detail__tag">Machine Learning</span>
                                    <span class="project-detail__tag">Deep Learning</span>
                                    <span class="project-detail__tag">Research</span>
                                </div>
                            </div>
                        </div>

                        <a href="https://github.com/samnart/ml-experiments" class="project-detail__github" target="_blank" rel="noopener">
                            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor">
                                <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                            </svg>
                            View on GitHub
                        </a>
                    </div>

                    <p class="project-detail__intro">
                        A collection of machine learning experiments and Jupyter notebooks exploring various algorithms, architectures, and techniques. Built as a learning resource while studying ML fundamentals and modern deep learning approaches.
                    </p>
                </header>

                <!-- Content -->
                <div class="project-detail__content">
                    <!-- Overview -->
                    <section class="project-detail__section">
                        <h2 class="project-detail__section-title">Overview</h2>
                        <div class="project-detail__text">
                            <p>
                                This repository is my ML learning lab - a place to implement algorithms from scratch, experiment with different architectures, and build intuition for how these models actually work beyond just calling library functions.
                            </p>
                            <p>
                                Each notebook focuses on a specific concept, starting with mathematical foundations and building up to working implementations with visualizations and experiments.
                            </p>
                        </div>
                    </section>

                    <!-- Key Features -->
                    <section class="project-detail__section">
                        <h2 class="project-detail__section-title">Experiments</h2>
                        <div class="project-detail__features">
                            <div class="project-detail__feature">
                                <div class="project-detail__feature-icon">
                                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M7 12l3-3 3 3 4-4M8 21l4-4 4 4M3 4h18M4 4h16v12a1 1 0 01-1 1H5a1 1 0 01-1-1V4z"/>
                                    </svg>
                                </div>
                                <div class="project-detail__feature-content">
                                    <h4>Neural Networks from Scratch</h4>
                                    <p>Implementing forward pass, backpropagation, and gradient descent using only NumPy to understand the fundamentals.</p>
                                </div>
                            </div>

                            <div class="project-detail__feature">
                                <div class="project-detail__feature-icon">
                                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 16l4.586-4.586a2 2 0 012.828 0L16 16m-2-2l1.586-1.586a2 2 0 012.828 0L20 14m-6-6h.01M6 20h12a2 2 0 002-2V6a2 2 0 00-2-2H6a2 2 0 00-2 2v12a2 2 0 002 2z"/>
                                    </svg>
                                </div>
                                <div class="project-detail__feature-content">
                                    <h4>CNN Architectures</h4>
                                    <p>Implementing and comparing LeNet, AlexNet, VGG, and ResNet for image classification tasks.</p>
                                </div>
                            </div>

                            <div class="project-detail__feature">
                                <div class="project-detail__feature-icon">
                                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 9l3 3-3 3m5 0h3M5 20h14a2 2 0 002-2V6a2 2 0 00-2-2H5a2 2 0 00-2 2v12a2 2 0 002 2z"/>
                                    </svg>
                                </div>
                                <div class="project-detail__feature-content">
                                    <h4>Sequence Models</h4>
                                    <p>RNNs, LSTMs, and Transformers for text classification and sequence prediction tasks.</p>
                                </div>
                            </div>

                            <div class="project-detail__feature">
                                <div class="project-detail__feature-icon">
                                    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 19v-6a2 2 0 00-2-2H5a2 2 0 00-2 2v6a2 2 0 002 2h2a2 2 0 002-2zm0 0V9a2 2 0 012-2h2a2 2 0 012 2v10m-6 0a2 2 0 002 2h2a2 2 0 002-2m0 0V5a2 2 0 012-2h2a2 2 0 012 2v14a2 2 0 01-2 2h-2a2 2 0 01-2-2z"/>
                                    </svg>
                                </div>
                                <div class="project-detail__feature-content">
                                    <h4>Classical ML</h4>
                                    <p>Decision trees, random forests, SVMs, and ensemble methods with scikit-learn.</p>
                                </div>
                            </div>
                        </div>
                    </section>

                    <!-- Highlight Project -->
                    <section class="project-detail__section">
                        <h2 class="project-detail__section-title">Featured: Attention Visualization</h2>
                        <div class="project-detail__text">
                            <p>
                                One of my favorite experiments visualizes attention weights in a transformer model. By extracting and plotting attention patterns, you can see what the model "focuses on" when making predictions.
                            </p>
                            <p>
                                This visualization helped me understand why transformers are so effective for NLP tasks - they can learn to attend to relevant context regardless of distance in the input sequence.
                            </p>
                        </div>

                        <div class="project-detail__callout">
                            <p>The attention visualization notebook has been starred by 50+ researchers and is used in several university courses as teaching material.</p>
                        </div>
                    </section>

                    <!-- Tech Stack -->
                    <section class="project-detail__section">
                        <h2 class="project-detail__section-title">Tech Stack</h2>
                        <div class="project-detail__stack">
                            <span class="project-detail__stack-item">Python</span>
                            <span class="project-detail__stack-item">PyTorch</span>
                            <span class="project-detail__stack-item">scikit-learn</span>
                            <span class="project-detail__stack-item">NumPy</span>
                            <span class="project-detail__stack-item">Matplotlib</span>
                            <span class="project-detail__stack-item">Jupyter</span>
                            <span class="project-detail__stack-item">Weights & Biases</span>
                        </div>
                    </section>

                    <!-- What I Learned -->
                    <section class="project-detail__section">
                        <h2 class="project-detail__section-title">What I Learned</h2>
                        <div class="project-detail__text">
                            <p>
                                Implementing algorithms from scratch, even inefficiently, builds understanding that no amount of library usage can match. Debugging why your gradients are exploding or your model isn't learning teaches you far more than achieving good accuracy on a benchmark.
                            </p>
                            <p>
                                I also learned about reproducibility - the importance of seeding random numbers, logging hyperparameters, and versioning both code and data.
                            </p>
                        </div>
                    </section>
                </div>

                <!-- Footer Navigation -->
                <footer class="project-detail__footer">
                    <nav class="project-detail__nav">
                        <a href="/projects/data-pipeline/" class="project-detail__nav-link">
                            <span>Previous Project</span>
                            <span>data-pipeline</span>
                        </a>
                        <a href="/projects/skill-link/" class="project-detail__nav-link project-detail__nav-link--next">
                            <span>Next Project</span>
                            <span>skill-link</span>
                        </a>
                    </nav>
                </footer>
            </article>
        </div>
    </main>

    <div id="footer" aria-busy="true"></div>

    <script src="/js/main.js"></script>
    <script src="/js/include.js"></script>
</body>
</html>
